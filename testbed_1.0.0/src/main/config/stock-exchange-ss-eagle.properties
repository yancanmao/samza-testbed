# Application / Job
app.class=samzatask.stock.StockExchangeApp
job.factory.class=org.apache.samza.job.yarn.ScalableYarnJobFactory
job.name=stock-exchange
job.container.single.thread.mode=true
#job.container.thread.pool.size=0
job.container.count=16
job.id=725
job.default.system=kafka
job.debounce.time.ms=5000
#Manual Delay
#job.delay.time.ms=5
job.delay.time.us=5000

task.opts=-Xms4096M -Xmx4096M

task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka

# YARN
#yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.package.path=hdfs://eagle:9000/testbed/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.resourcemanager.address=eagle:8032
yarn.container.memory.mb=6144
yarn.am.container.memory.mb=6144

job.controller.factory=org.apache.samza.controller.streamswitch.LatencyGuarantorFactory

# StreamSwitch
# system metrics configs
streamswitch.system.metrics_interval=100
streamswitch.system.migration_interval=60000
streamswitch.system.warmup_time=40000
streamswitch.system.max_executors=30
streamswitch.system.metrics_retriever.factory=org.apache.samza.controller.streamswitch.StockMetricsRetrieverFactory
streamswitch.system.l_low=100
streamswitch.system.l_high=100
streamswitch.system.conservative=0.6
streamswitch.system.initialservicerate=0.2
#metrics retriever configs
yarn.web.address=eagle:8088
topic.number=1
topic.1.name=stock_sb
#user requirements
streamswitch.requirement.window=1000
streamswitch.requirement.latency=1000

task.name.grouper.factory=org.apache.samza.container.grouper.task.GroupByContainerIdsFactory

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory
metrics.reporter.snapshot.interval=2

# kafka
systems.kafka.consumer.zookeeper.connect=eagle:2181
systems.kafka.producer.bootstrap.servers=eagle:9092
job.coordinator.zk.connect=eagle:2181

#back-pressure
systems.kafka.samza.fetch.threshold=2560000

## Serializers
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory

job.coordinator.factory=org.apache.samza.zk.FollowerJobCoordinatorFactory
task.execute=bin/run-processor.sh

# registry a serde for orderpool
serializers.registry.orderpool.class=samzatask.stock.OrderPoolSerdeFactory

# Key-value storage
stores.stock-exchange-sell.factory=org.apache.samza.storage.kv.inmemory.InMemoryKeyValueStorageEngineFactory
#stores.stock-exchange-sell.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.stock-exchange-sell.changelog=kafka.stock-exchange-sell-changelog
stores.stock-exchange-sell.key.serde=string
stores.stock-exchange-sell.msg.serde=orderpool

stores.stock-exchange-buy.factory=org.apache.samza.storage.kv.inmemory.InMemoryKeyValueStorageEngineFactory
#stores.stock-exchange-buy.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.stock-exchange-buy.changelog=kafka.stock-exchange-buy-changelog
stores.stock-exchange-buy.key.serde=string
stores.stock-exchange-buy.msg.serde=orderpool

#systems.kafka.consumer.zookeeper.connect=alligator:2181
#systems.kafka.producer.bootstrap.servers=alligator:9092,buffalo:9092
#job.coordinator.zk.connect=alligator:2181

## Application / Job
#app.class=samzatask.stock.StockExchangeApp
#job.name=stock-exchange
#job.changelog.system=kafka
##task.name.grouper.factory=org.apache.samza.container.grouper.task.SingleContainerGrouperFactory
#processor.id=0
##systems.kafka.default.stream.samza.offset.default=oldest
#job.coordinator.zk.connect=localhost:2181
#job.default.system=kafka
